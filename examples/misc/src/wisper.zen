


MultiHeadAttention: {
    n_head: Int.I8(8),
    query: NN.Linear(512, 512),
    key: NN.Linear(512, 512),
    value: NN.Linear(512, 512),
    out: NN.Linear(512, 512),
}

new: fn {
    args: {
        n_head: Int.I8(8),
    },
    return: { MultiHeadAttention },
    body: {
        return(MultiHeadAttention(n_head))
    },
}

forward: fn {
    args: {
        self: MultiHeadAttention,
        x: Tensor,
        mask: Tensor,
    },
    return: { Tensor, },
    body: {
        batch_size: x.shape[0]
        query: self.query(x).reshape(batch_size, -1, self.n_head, 64).transpose(1, 2)
        key: self.key(x).reshape(batch_size, -1, self.n_head, 64).transpose(1, 2)
        value: self.value(x).reshape(batch_size, -1, self.n_head, 64).transpose(1, 2)
        attn: Attention(query, key, value, mask)
        attn: attn.transpose(1, 2).reshape(batch_size, -1, self.n_head * 64)
        return(self.out(attn))
    },
}

